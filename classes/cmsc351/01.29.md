# cmsc351 / 01.29

## big o notation.

Suppose we have an algorithm that processes $n$ elements. We might want to know:

- How does running time increase as $n$​ goes up?
- How does memory usage increase as $n$​ goes up?
  - You can often have very time-efficient algorithms with very high memory usage.

Suppose algorithm $A_1$​ takes $5n$​ time, while $A_2$​ takes $n^2$​ time. $A_1$​ has a lower time complexity, but might not always be the better choice. ($A_2$​ might be more memory efficient, etc.)

Big $\mathbb{O}$ is formally defined as follows:
$$
f(x) = \mathbb{O}(g(x))  \text{ if }\exists (x_0, c) > 0 \text{ s.t. } \forall (x) \geq x_0, f(x) \leq cg(x)
$$
That last part is important: $f(x) \leq cg(x)$. If an algorithm was $O(x^2)$, it would have to run in less than $cx^2$ for all $x$ values and some constant $c$.

**Show** that $3x = \mathbb{O}(x)$.

- **Answer:** $3x \leq cx$ for $c \geq 3, x_0 = 0$.

**Show** that $2x^2 + 1 = \mathbb{O}(x^2)$.

- Let $c = 3$.

  $2x^2 + 1 \leq 3x^2 \Rightarrow 1 \leq x^2$, which is true for $x \geq 1$ (our minimum).

  **Answer:** $2x^2 + 1 \leq 3x^2$ for $c \geq 3, x_0 = 1$.

$O(...)$​ contains the leading term and no constants. Sometimes $O$ might have multiple, non-constant variables. For example, a function iterating through matrix of size $n \times m$ might have $O(nm)$ runtime.